{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Tagging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFdC42x5Owez1yN4lB2N2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DerNiccoo/TheEarlyBird/blob/main/Aufgabe5/Nico/LSTM_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEGgFbzRVWz_",
        "outputId": "29fcab7f-38e4-4144-90e6-57da19fd45af"
      },
      "source": [
        "!pip install -U spacy[cuda100] de\n",
        "!python -m spacy download de"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy[cuda100] in /usr/local/lib/python3.6/dist-packages (2.3.4)\n",
            "Requirement already up-to-date: de in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (2.0.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: cupy-cuda100<8.0.0,>=5.0.0b4; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (7.8.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<8.0.0,>=5.0.0b4; extra == \"cuda100\"->spacy[cuda100]) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<8.0.0,>=5.0.0b4; extra == \"cuda100\"->spacy[cuda100]) (0.5)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (3.4.0)\n",
            "Requirement already satisfied: de_core_news_sm==2.3.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz#egg=de_core_news_sm==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.3.0) (2.3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.4)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYjc0UGINABA"
      },
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/tblock/10kGNAD/master/train.csv'\n",
        "df_train = pd.read_csv(url, error_bad_lines=False, sep=';', usecols=range(2), names=['labels','text'])\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/tblock/10kGNAD/master/test.csv'\n",
        "df_test = pd.read_csv(url, error_bad_lines=False, sep=';', usecols=range(2), names=['labels','text'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ClxiHiOWuo"
      },
      "source": [
        "df_train = df_train.loc[(df_train['labels'] == 'Sport') | (df_train['labels'] == 'Wirtschaft')]\n",
        "df_test = df_test.loc[(df_test['labels'] == 'Sport') | (df_test['labels'] == 'Wirtschaft')]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IoaoVJGPO9UO",
        "outputId": "44722e17-a2ce-48d5-d985-5fbe7ac6cba5"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sport</td>\n",
              "      <td>21-Jähriger fällt wohl bis Saisonende aus. Wie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Der Welser Stempelhersteller verbreitert sich ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sport</td>\n",
              "      <td>Traditionsklub setzt sich gegen den FC Utrecht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sport</td>\n",
              "      <td>Abschiedstournee für Guardiola beginnt beim HS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9221</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Austria Glas Recycling appelliert an Bevölkeru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9228</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Kein Kommentar, ob Raffinerie in Schwechat ode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9235</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Günter Geyer zieht nach wie vor die Fäden – El...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9238</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Der heimische Baukonzern zieht einen Großauftr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9242</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Derzeit Konzeptgruppe in Berlin – Kein Komment...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2351 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          labels                                               text\n",
              "0          Sport  21-Jähriger fällt wohl bis Saisonende aus. Wie...\n",
              "3     Wirtschaft  Putin: \"Einigung, dass wir Menge auf Niveau vo...\n",
              "5     Wirtschaft  Der Welser Stempelhersteller verbreitert sich ...\n",
              "6          Sport  Traditionsklub setzt sich gegen den FC Utrecht...\n",
              "9          Sport  Abschiedstournee für Guardiola beginnt beim HS...\n",
              "...          ...                                                ...\n",
              "9221  Wirtschaft  Austria Glas Recycling appelliert an Bevölkeru...\n",
              "9228  Wirtschaft  Kein Kommentar, ob Raffinerie in Schwechat ode...\n",
              "9235  Wirtschaft  Günter Geyer zieht nach wie vor die Fäden – El...\n",
              "9238  Wirtschaft  Der heimische Baukonzern zieht einen Großauftr...\n",
              "9242  Wirtschaft  Derzeit Konzeptgruppe in Berlin – Kein Komment...\n",
              "\n",
              "[2351 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTRfxwzYPVM9"
      },
      "source": [
        "import string\n",
        "\n",
        "valid_chars = string.ascii_letters + 'ÄÖÜäöüß–' + string.punctuation + string.digits + string.whitespace\n",
        "\n",
        "def check_chars(row):\n",
        "  for char in row:\n",
        "    if char not in valid_chars:\n",
        "      return True\n",
        "\n",
        "  return False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxKmltCVSKyb"
      },
      "source": [
        "df_train = df_train[df_train['text'].apply(check_chars) == False]\n",
        "df_test = df_test[df_test['text'].apply(check_chars) == False]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "edUtBSlWrg_u",
        "outputId": "ef80d215-54f4-4218-8f45-a3cb8efd6613"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sport</td>\n",
              "      <td>21-Jähriger fällt wohl bis Saisonende aus. Wie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Der Welser Stempelhersteller verbreitert sich ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sport</td>\n",
              "      <td>Traditionsklub setzt sich gegen den FC Utrecht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sport</td>\n",
              "      <td>Abschiedstournee für Guardiola beginnt beim HS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9221</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Austria Glas Recycling appelliert an Bevölkeru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9228</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Kein Kommentar, ob Raffinerie in Schwechat ode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9235</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Günter Geyer zieht nach wie vor die Fäden – El...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9238</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Der heimische Baukonzern zieht einen Großauftr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9242</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Derzeit Konzeptgruppe in Berlin – Kein Komment...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2163 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          labels                                               text\n",
              "0          Sport  21-Jähriger fällt wohl bis Saisonende aus. Wie...\n",
              "3     Wirtschaft  Putin: \"Einigung, dass wir Menge auf Niveau vo...\n",
              "5     Wirtschaft  Der Welser Stempelhersteller verbreitert sich ...\n",
              "6          Sport  Traditionsklub setzt sich gegen den FC Utrecht...\n",
              "9          Sport  Abschiedstournee für Guardiola beginnt beim HS...\n",
              "...          ...                                                ...\n",
              "9221  Wirtschaft  Austria Glas Recycling appelliert an Bevölkeru...\n",
              "9228  Wirtschaft  Kein Kommentar, ob Raffinerie in Schwechat ode...\n",
              "9235  Wirtschaft  Günter Geyer zieht nach wie vor die Fäden – El...\n",
              "9238  Wirtschaft  Der heimische Baukonzern zieht einen Großauftr...\n",
              "9242  Wirtschaft  Derzeit Konzeptgruppe in Berlin – Kein Komment...\n",
              "\n",
              "[2163 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9mcU5DJSSdY",
        "outputId": "d6c1f8b6-3406-4c0f-bc79-06a7e7672dbe"
      },
      "source": [
        "import spacy\n",
        "gpu = spacy.prefer_gpu()\n",
        "print('GPU:', gpu)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoUME67xSxRT"
      },
      "source": [
        "nlp = spacy.load('de')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TogjAUgMSzyX"
      },
      "source": [
        "vocab = {}\n",
        "\n",
        "for index, row in df_train.iterrows():\n",
        "  doc = nlp(row['text'])\n",
        "  for token in doc:\n",
        "    if token.text in vocab:\n",
        "      vocab[token.text] += 1\n",
        "    else:\n",
        "      vocab[token.text] = 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni0IAvzIUgsJ"
      },
      "source": [
        "sorted_vocab = dict(sorted(vocab.items(), key=lambda item: item[1], reverse=True))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzqyjakGYcXt"
      },
      "source": [
        "vocab = list(sorted_vocab)[:5000]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdqsctIEZoh4"
      },
      "source": [
        "word_to_ix = {}\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  word_to_ix[word] = index\n",
        "\n",
        "tag_to_ix = {\"Sport\": 0, \"Wirtschaft\": 1}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "684uiIhxZyYf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCJSpjxrs-tE",
        "outputId": "5c542679-a0c6-4ec5-835c-c0238eeb5257"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLkMfuaRe0z1"
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "  idxs = []\n",
        "\n",
        "  for w in seq:\n",
        "    if w in to_ix:\n",
        "      idxs.append(to_ix[w])\n",
        "\n",
        "  return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def target_tensor(target):\n",
        "  tensor = torch.zeros(2, dtype=torch.long)\n",
        "  tensor[target[0]] = 1\n",
        "  return tensor\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVipzc5EdOy9"
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw_m2vkkeC-1",
        "outputId": "4fe8ba03-82ac-4fea-954a-94931af4c1d1"
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# See what the scores are before training\n",
        "# Note that element i,j of the output is the score for tag j for word i.\n",
        "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "count = 0\n",
        "for epoch in range(5):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    count = 0\n",
        "    for index, row in df_train.iterrows():\n",
        "      sentence = row['text'].split()\n",
        "      tags = row['labels'].split()\n",
        "      # Step 1. Remember that Pytorch accumulates gradients.\n",
        "      # We need to clear them out before each instance\n",
        "      model.zero_grad()\n",
        "\n",
        "      # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "      # Tensors of word indices.\n",
        "      sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "      targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "      if len(sentence_in) == 0:\n",
        "        print(\"skipped\")\n",
        "        continue\n",
        "\n",
        "      # Step 3. Run our forward pass.\n",
        "      tag_scores = model(sentence_in)\n",
        "\n",
        "      # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "      #  calling optimizer.step()\n",
        "\n",
        "      target = target_tensor(targets)\n",
        "      target = torch.reshape(targets, (1, 1))\n",
        "\n",
        "      output = tag_scores[-1]\n",
        "      output = torch.reshape(output, (1, output.shape[0]))\n",
        "\n",
        "      loss = loss_function(output, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if count % 500 == 0:\n",
        "        print('%s (%d %d%%) %.4f' % (timeSince(start), count, count / len(df_train) * 100, loss))\n",
        "      count += 1\n",
        "\n",
        "    print('%s Epoch %d / 5' % (timeSince(start), epoch + 1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 0s (0 0%) 0.6847\n",
            "skipped\n",
            "0m 4s (500 23%) 0.9015\n",
            "0m 9s (1000 46%) 0.3120\n",
            "0m 15s (1500 69%) 0.2233\n",
            "0m 20s (2000 92%) 0.4414\n",
            "0m 22s Epoch 1 / 5\n",
            "0m 25s (2500 115%) 0.0686\n",
            "skipped\n",
            "0m 30s (3000 138%) 0.0180\n",
            "0m 35s (3500 161%) 0.4277\n",
            "0m 40s (4000 184%) 0.7564\n",
            "0m 43s Epoch 2 / 5\n",
            "0m 45s (4500 208%) 0.0395\n",
            "skipped\n",
            "0m 50s (5000 231%) 0.1754\n",
            "0m 55s (5500 254%) 1.2956\n",
            "1m 0s (6000 277%) 0.4596\n",
            "1m 5s Epoch 3 / 5\n",
            "1m 5s (6500 300%) 0.1060\n",
            "skipped\n",
            "1m 10s (7000 323%) 0.0001\n",
            "1m 15s (7500 346%) 0.0000\n",
            "1m 20s (8000 369%) 0.0000\n",
            "1m 26s (8500 392%) 0.2929\n",
            "1m 27s Epoch 4 / 5\n",
            "1m 31s (9000 416%) 0.0073\n",
            "skipped\n",
            "1m 36s (9500 439%) 0.2149\n",
            "1m 41s (10000 462%) 0.0028\n",
            "1m 46s (10500 485%) 0.0001\n",
            "1m 49s Epoch 5 / 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlC16s-8xc5u"
      },
      "source": [
        "cats = ['Sport', 'Wirtschaft']\n",
        "\n",
        "def test_sentence(sentence):\n",
        "  sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "  output = model(sentence_in)\n",
        "\n",
        "  _, topi = output[-1].topk(1)\n",
        "\n",
        "  return cats[topi]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNHoCVBMzcQS"
      },
      "source": [
        "def test_model():\n",
        "\n",
        "  correct = 0\n",
        "\n",
        "  for index, row in df_test.iterrows():\n",
        "    output = test_sentence(row['text'].split())\n",
        "    if output == row['labels']:\n",
        "      correct += 1\n",
        "\n",
        "  print('Acc: {:.2f}'.format(correct / len(df_test) * 100))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nq3gG3S0pn3",
        "outputId": "5977f477-306c-41cf-a558-d68aa678a30c"
      },
      "source": [
        "test_model()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 85.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iUPWZu71k_s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}