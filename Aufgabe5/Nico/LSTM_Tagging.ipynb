{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Tagging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYgifzXjwsWWTUC0B8opgb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DerNiccoo/TheEarlyBird/blob/main/Aufgabe5/Nico/LSTM_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEGgFbzRVWz_",
        "outputId": "aec02730-212c-4936-e20a-b4847266d264"
      },
      "source": [
        "!pip install -U spacy[cuda100] de\n",
        "!python -m spacy download de"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy[cuda100]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/b2/12466d3018bb84b039139ef76436ea7a01e98125c2aee6a81e527eb4ebe1/spacy-2.3.4-cp36-cp36m-manylinux2014_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 13.3MB/s \n",
            "\u001b[?25hCollecting de\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/b8/ee2e5c22775450d2a8751273a4b3cfa6e47cdb6393dd803b6317a85d213c/de-0.1.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (2.0.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (3.0.4)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/c9/ce2e03720a5647fd90da575325376ff258653a05f357aa970fd87e6c1a55/thinc-7.4.3-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.4MB/s \n",
            "\u001b[?25hCollecting cupy-cuda100<8.0.0,>=5.0.0b4; extra == \"cuda100\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/4c/3454f4e633e721f983ba19d54983734d9276ced336178d264533f06d12a6/cupy_cuda100-7.8.0-cp36-cp36m-manylinux1_x86_64.whl (348.0MB)\n",
            "\u001b[K     |████████████████████████████████| 348.0MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<8.0.0,>=5.0.0b4; extra == \"cuda100\"->spacy[cuda100]) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<8.0.0,>=5.0.0b4; extra == \"cuda100\"->spacy[cuda100]) (0.5)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (3.4.0)\n",
            "Building wheels for collected packages: de\n",
            "  Building wheel for de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de: filename=de-0.1-cp36-none-any.whl size=1158 sha256=f33dba767ec4e62291e768dc361f2b2327b217e2b33d05522d0258dbf27e8d1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/16/b9/46fac6c03128929538323f5457e947af752b7c58d4c7783f04\n",
            "Successfully built de\n",
            "Installing collected packages: thinc, cupy-cuda100, spacy, de\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed cupy-cuda100-7.8.0 de-0.1 spacy-2.3.4 thinc-7.4.3\n",
            "Collecting de_core_news_sm==2.3.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.3.0) (2.3.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (50.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.11.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.3.0-cp36-none-any.whl size=14907580 sha256=75f5078c8254a4d6d6424c425ff7518c42476113725d3fca27e3b76c335b47b2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-htys82tm/wheels/db/f3/1e/0df0f27eee12bd1aaa94bcfef11b01eca62f90b9b9a0ce08fd\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYjc0UGINABA"
      },
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/tblock/10kGNAD/master/train.csv'\n",
        "df_train = pd.read_csv(url, error_bad_lines=False, sep=';', usecols=range(2), names=['labels','text'])\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/tblock/10kGNAD/master/test.csv'\n",
        "df_test = pd.read_csv(url, error_bad_lines=False, sep=';', usecols=range(2), names=['labels','text'])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ClxiHiOWuo"
      },
      "source": [
        "df_train = df_train.loc[(df_train['labels'] == 'Sport') | (df_train['labels'] == 'Wirtschaft')]\n",
        "df_test = df_test.loc[(df_test['labels'] == 'Sport') | (df_test['labels'] == 'Wirtschaft')]"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IoaoVJGPO9UO",
        "outputId": "a3e2ee15-6b57-47e3-d5d2-b5224841f743"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sport</td>\n",
              "      <td>21-Jähriger fällt wohl bis Saisonende aus. Wie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sport</td>\n",
              "      <td>Traditionsklub setzt sich gegen den FC Utrecht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sport</td>\n",
              "      <td>Abschiedstournee für Guardiola beginnt beim HS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sport</td>\n",
              "      <td>SSC nach 5:1-Erfolg bei Robert Guchers Frosino...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9221</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Austria Glas Recycling appelliert an Bevölkeru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9228</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Kein Kommentar, ob Raffinerie in Schwechat ode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9235</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Günter Geyer zieht nach wie vor die Fäden – El...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9238</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Der heimische Baukonzern zieht einen Großauftr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9242</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Derzeit Konzeptgruppe in Berlin – Kein Komment...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2080 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          labels                                               text\n",
              "0          Sport  21-Jähriger fällt wohl bis Saisonende aus. Wie...\n",
              "3     Wirtschaft  Putin: \"Einigung, dass wir Menge auf Niveau vo...\n",
              "6          Sport  Traditionsklub setzt sich gegen den FC Utrecht...\n",
              "9          Sport  Abschiedstournee für Guardiola beginnt beim HS...\n",
              "10         Sport  SSC nach 5:1-Erfolg bei Robert Guchers Frosino...\n",
              "...          ...                                                ...\n",
              "9221  Wirtschaft  Austria Glas Recycling appelliert an Bevölkeru...\n",
              "9228  Wirtschaft  Kein Kommentar, ob Raffinerie in Schwechat ode...\n",
              "9235  Wirtschaft  Günter Geyer zieht nach wie vor die Fäden – El...\n",
              "9238  Wirtschaft  Der heimische Baukonzern zieht einen Großauftr...\n",
              "9242  Wirtschaft  Derzeit Konzeptgruppe in Berlin – Kein Komment...\n",
              "\n",
              "[2080 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTRfxwzYPVM9"
      },
      "source": [
        "import string\n",
        "\n",
        "valid_chars = string.ascii_letters + 'ÄÖÜäöüß-' + string.punctuation + string.digits + string.whitespace\n",
        "\n",
        "def check_chars(row):\n",
        "  for char in row:\n",
        "    if char not in valid_chars:\n",
        "      return True\n",
        "\n",
        "  return False"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxKmltCVSKyb"
      },
      "source": [
        "df_train = df_train[df_train['text'].apply(check_chars) == True]\n",
        "df_test = df_test[df_test['text'].apply(check_chars) == True]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9mcU5DJSSdY",
        "outputId": "9be0a2f7-472b-43a1-c436-467647ab4088"
      },
      "source": [
        "import spacy\n",
        "gpu = spacy.prefer_gpu()\n",
        "print('GPU:', gpu)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoUME67xSxRT"
      },
      "source": [
        "nlp = spacy.load('de')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TogjAUgMSzyX"
      },
      "source": [
        "vocab = {}\n",
        "\n",
        "for index, row in df_train.iterrows():\n",
        "  doc = nlp(row['text'])\n",
        "  for token in doc:\n",
        "    if token.text in vocab:\n",
        "      vocab[token.text] += 1\n",
        "    else:\n",
        "      vocab[token.text] = 0"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni0IAvzIUgsJ"
      },
      "source": [
        "sorted_vocab = dict(sorted(vocab.items(), key=lambda item: item[1], reverse=True))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzqyjakGYcXt"
      },
      "source": [
        "vocab = list(sorted_vocab)[:5000]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdqsctIEZoh4"
      },
      "source": [
        "word_to_ix = {}\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  word_to_ix[word] = index\n",
        "\n",
        "tag_to_ix = {\"Sport\": 0, \"Wirtschaft\": 1}"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "684uiIhxZyYf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCJSpjxrs-tE",
        "outputId": "780be457-ac52-422f-f858-cc05f99b519a"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLkMfuaRe0z1"
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "  idxs = []\n",
        "\n",
        "  for w in seq:\n",
        "    if w in to_ix:\n",
        "      idxs.append(to_ix[w])\n",
        "\n",
        "  return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def target_tensor(target):\n",
        "  tensor = torch.zeros(2, dtype=torch.long)\n",
        "  tensor[target[0]] = 1\n",
        "  return tensor\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVipzc5EdOy9"
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw_m2vkkeC-1",
        "outputId": "d1ae385b-87da-41ed-e4b5-aaeab2efd071"
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# See what the scores are before training\n",
        "# Note that element i,j of the output is the score for tag j for word i.\n",
        "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(5):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    for index, row in df_train.iterrows():\n",
        "      sentence = row['text'].split()\n",
        "      tags = row['labels'].split()\n",
        "      # Step 1. Remember that Pytorch accumulates gradients.\n",
        "      # We need to clear them out before each instance\n",
        "      model.zero_grad()\n",
        "\n",
        "      # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "      # Tensors of word indices.\n",
        "      sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "      targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "      if len(sentence_in) == 0:\n",
        "        continue\n",
        "\n",
        "      # Step 3. Run our forward pass.\n",
        "      tag_scores = model(sentence_in)\n",
        "\n",
        "      # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "      #  calling optimizer.step()\n",
        "\n",
        "      target = target_tensor(targets)\n",
        "      target = torch.reshape(targets, (1, 1))\n",
        "\n",
        "      output = tag_scores[-1]\n",
        "      output = torch.reshape(output, (1, output.shape[0]))\n",
        "\n",
        "      loss = loss_function(output, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if index % 500 == 0:\n",
        "        print('%s (%d %d%%) %.4f' % (timeSince(start), index, index / len(df_train) * 100, loss))\n",
        "\n",
        "    print('%s Epoch %d / 5' % (timeSince(start), epoch + 1))"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 0s (0 0%) 0.6752\n",
            "0m 6s (2500 106%) 0.5919\n",
            "0m 8s (3500 148%) 0.2074\n",
            "0m 16s (6500 276%) 0.1102\n",
            "0m 17s (7000 297%) 0.5245\n",
            "0m 23s Epoch 1 / 5\n",
            "0m 23s (0 0%) 0.1196\n",
            "0m 29s (2500 106%) 0.2178\n",
            "0m 32s (3500 148%) 0.0502\n",
            "0m 40s (6500 276%) 0.0339\n",
            "0m 41s (7000 297%) 0.0494\n",
            "0m 47s Epoch 2 / 5\n",
            "0m 47s (0 0%) 0.0156\n",
            "0m 53s (2500 106%) 0.0343\n",
            "0m 55s (3500 148%) 0.4604\n",
            "1m 3s (6500 276%) 0.0098\n",
            "1m 4s (7000 297%) 0.0094\n",
            "1m 10s Epoch 3 / 5\n",
            "1m 10s (0 0%) 0.0059\n",
            "1m 16s (2500 106%) 0.0631\n",
            "1m 19s (3500 148%) 0.0216\n",
            "1m 26s (6500 276%) 0.0077\n",
            "1m 27s (7000 297%) 0.0350\n",
            "1m 33s Epoch 4 / 5\n",
            "1m 33s (0 0%) 0.3078\n",
            "1m 39s (2500 106%) 0.0014\n",
            "1m 42s (3500 148%) 0.0717\n",
            "1m 49s (6500 276%) 0.0056\n",
            "1m 51s (7000 297%) 0.0026\n",
            "1m 56s Epoch 5 / 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlC16s-8xc5u"
      },
      "source": [
        "cats = ['Sport', 'Wirtschaft']\n",
        "\n",
        "def test_sentence(sentence):\n",
        "  sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "  output = model(sentence_in)\n",
        "\n",
        "  _, topi = output[-1].topk(1)\n",
        "\n",
        "  return cats[topi]"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNHoCVBMzcQS"
      },
      "source": [
        "def test_model():\n",
        "\n",
        "  correct = 0\n",
        "\n",
        "  for index, row in df_test.iterrows():\n",
        "    output = test_sentence(row['text'].split())\n",
        "    if output == row['labels']:\n",
        "      correct += 1\n",
        "\n",
        "  print('Acc: {:.2f}'.format(correct / len(df_test) * 100))"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nq3gG3S0pn3",
        "outputId": "26953cc8-8074-4858-f2d2-767321a16b1c"
      },
      "source": [
        "test_model()"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 89.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iUPWZu71k_s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}