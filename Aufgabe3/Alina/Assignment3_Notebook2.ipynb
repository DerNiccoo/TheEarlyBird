{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3_Notebook2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1J8xB3S4idI33-W5ETowRou-faUaAKyyX",
      "authorship_tag": "ABX9TyPemwKytE/NP4+k+rhou00F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DerNiccoo/TheEarlyBird/blob/main/Aufgabe3/Alina/Assignment3_Notebook2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdw2-5_PY8N2"
      },
      "source": [
        "# **Notebook 2: Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2BZ8Wgc2dBk"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XpgBqlp21vv"
      },
      "source": [
        "#Choose a device: GPU\n",
        "device_gpu = torch.device(\"cuda:0\")\n",
        "device_cpu = torch.device('cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WQUJWeE3x-C"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQJb8qS9YXKF"
      },
      "source": [
        "# **1. Load a reduced dataset for transfer learning that:**\n",
        "  1. Only contains the classes „ship“ and „truck“\n",
        "  2. Only contains the first 50 images of the original dataset that are either „ship“ or „truck“."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivZHiDjaZU9s"
      },
      "source": [
        "class CIFAR_X(torchvision.datasets.CIFAR10):\n",
        "\n",
        "    def __init__(self, *args, exclude_list=[], **kwargs):\n",
        "        super(CIFAR_X, self).__init__(*args, **kwargs)\n",
        "\n",
        "        if exclude_list == []:\n",
        "            return\n",
        "\n",
        "        labels = np.array(self.targets)\n",
        "        exclude = np.array(exclude_list).reshape(1, -1)\n",
        "        filter = ~(labels.reshape(-1, 1) == exclude).any(axis=1)\n",
        "\n",
        "        labels[labels == 8] = 0\n",
        "        labels[labels == 9] = 1\n",
        "\n",
        "        self.data = self.data[filter]\n",
        "        self.targets = labels[filter].tolist()\n",
        "\n",
        "        self.data = self.data[:50]\n",
        "        self.targets = self.targets[:50]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG8eByx8aZOg",
        "outputId": "ccd05bfa-03b0-4add-8f14-c31065357ea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "                  \n",
        "trainset = CIFAR_X(root='./data', train=True, download=True, transform = transform, exclude_list=[0,1,2,3,4,5,6,7])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = CIFAR_X(root='./data', train=False, download=True, transform = transform, exclude_list=[0,1,2,3,4,5,6,7])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwX78D2Kde7h"
      },
      "source": [
        "# **2. Apply transfer learning by loading the model that was trained on the eight CIFAR classes (Notebook 1) and do the following experiments:**\n",
        "\n",
        "i. Re-initalize the last fully connected layer to predict on two classes.<br>\n",
        "ii. Train on the 50 training images (as on the last slide) with the model using two different approaches:<br>\n",
        "> a. Fine-tune all parameters (i.e. do not freeze parameters but reduce learning rate).<br>\n",
        "> b. Freeze all parameters expect the ones from the last fc-layer.<br>\n",
        "\n",
        "iii. Calculate the accuracy for both approaches on 50 test images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4H1hgxy1yRq",
        "outputId": "7f4d166e-16ba-41d3-976f-7841c3d89da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the trained Net\n",
        "PATH = '/content/drive/My Drive/KI_Lab/model'\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))\n",
        "\n",
        "#For GPU: \n",
        "#net.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
        "#net.to(device)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulA0izwddJXX",
        "outputId": "1ab1f4bf-63a2-431a-b5b8-29e915ba24d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Re-initialize the lastfully connected layer \n",
        "net.fc3 = nn.Linear(net.fc3.in_features, 2)\n",
        "net.to(device_cpu)\n",
        "#net.to(device_gpu)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvPpITFvh6Ud"
      },
      "source": [
        "# **Train Method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqKpX-9veMVd"
      },
      "source": [
        "def train(net, epochs, criterion, optimizer, device, trainloader):\n",
        "  t0 = time.time()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    # print every 10 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "  print('{} seconds'.format(time.time() - t0))\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exej0l1aJUm6"
      },
      "source": [
        "# **Test Method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIAQrkX7JKpi"
      },
      "source": [
        "def test(net, device, testloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the {} test images: {}%'.format(\n",
        "      len(testloader.dataset), 100 * correct / total))"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh-A4PQ6IQJp"
      },
      "source": [
        "> a. Fine-tune all parameters (i.e. do not freeze parameters but reduce learning rate).<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr9qI5bzh7kU",
        "outputId": "cba66c72-ac21-4da6-cc67-4ede69c58af8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for param in net.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "net.fc3 = nn.Linear(net.fc3.in_features, 2)\n",
        "net.to(device_cpu)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 30\n",
        "\n",
        "train(net, epochs, criterion, optimizer, device_cpu, trainloader)\n",
        "test(net, device_cpu, testloader)\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.540\n",
            "[2,    10] loss: 0.472\n",
            "[3,    10] loss: 0.350\n",
            "[4,    10] loss: 0.285\n",
            "[5,    10] loss: 0.247\n",
            "[6,    10] loss: 0.284\n",
            "[7,    10] loss: 0.142\n",
            "[8,    10] loss: 0.203\n",
            "[9,    10] loss: 0.179\n",
            "[10,    10] loss: 0.102\n",
            "[11,    10] loss: 0.085\n",
            "[12,    10] loss: 0.102\n",
            "[13,    10] loss: 0.107\n",
            "[14,    10] loss: 0.054\n",
            "[15,    10] loss: 0.045\n",
            "[16,    10] loss: 0.063\n",
            "[17,    10] loss: 0.028\n",
            "[18,    10] loss: 0.047\n",
            "[19,    10] loss: 0.035\n",
            "[20,    10] loss: 0.031\n",
            "[21,    10] loss: 0.027\n",
            "[22,    10] loss: 0.023\n",
            "[23,    10] loss: 0.017\n",
            "[24,    10] loss: 0.018\n",
            "[25,    10] loss: 0.013\n",
            "[26,    10] loss: 0.013\n",
            "[27,    10] loss: 0.012\n",
            "[28,    10] loss: 0.010\n",
            "[29,    10] loss: 0.011\n",
            "[30,    10] loss: 0.010\n",
            "3.6365394592285156 seconds\n",
            "Accuracy of the network on the 10000 test images: 82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNoPo80KiFv_",
        "outputId": "5d1005f8-311e-489c-f742-879b531d7087",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.000001, momentum=0.9)\n",
        "epochs = 30\n",
        "\n",
        "train(net, epochs, criterion, optimizer, device_cpu, trainloader)\n",
        "test(net, device_cpu, testloader)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.402\n",
            "[2,    10] loss: 0.433\n",
            "[3,    10] loss: 0.396\n",
            "[4,    10] loss: 0.424\n",
            "[5,    10] loss: 0.346\n",
            "[6,    10] loss: 0.382\n",
            "[7,    10] loss: 0.411\n",
            "[8,    10] loss: 0.420\n",
            "[9,    10] loss: 0.367\n",
            "[10,    10] loss: 0.413\n",
            "[11,    10] loss: 0.393\n",
            "[12,    10] loss: 0.373\n",
            "[13,    10] loss: 0.384\n",
            "[14,    10] loss: 0.392\n",
            "[15,    10] loss: 0.415\n",
            "[16,    10] loss: 0.400\n",
            "[17,    10] loss: 0.374\n",
            "[18,    10] loss: 0.391\n",
            "[19,    10] loss: 0.372\n",
            "[20,    10] loss: 0.389\n",
            "[21,    10] loss: 0.427\n",
            "[22,    10] loss: 0.404\n",
            "[23,    10] loss: 0.387\n",
            "[24,    10] loss: 0.434\n",
            "[25,    10] loss: 0.425\n",
            "[26,    10] loss: 0.377\n",
            "[27,    10] loss: 0.400\n",
            "[28,    10] loss: 0.396\n",
            "[29,    10] loss: 0.416\n",
            "[30,    10] loss: 0.387\n",
            "3.7235867977142334 seconds\n",
            "Accuracy of the network on the 10000 test images: 82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfnR7zW_ISmr"
      },
      "source": [
        "> b. Freeze all parameters expect the ones from the last fc-layer.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Zn7a9MH1Rd",
        "outputId": "114422f0-f08c-45ea-f356-9b670720b52d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "net.fc3 = nn.Linear(net.fc3.in_features, 2)\n",
        "net.to(device_cpu)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
        "epochs = 30\n",
        "\n",
        "train(net, epochs, criterion, optimizer, device_cpu, trainloader)\n",
        "test(net, device_cpu, testloader)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.756\n",
            "[2,    10] loss: 0.775\n",
            "[3,    10] loss: 0.743\n",
            "[4,    10] loss: 0.763\n",
            "[5,    10] loss: 0.746\n",
            "[6,    10] loss: 0.721\n",
            "[7,    10] loss: 0.754\n",
            "[8,    10] loss: 0.739\n",
            "[9,    10] loss: 0.727\n",
            "[10,    10] loss: 0.741\n",
            "[11,    10] loss: 0.709\n",
            "[12,    10] loss: 0.737\n",
            "[13,    10] loss: 0.718\n",
            "[14,    10] loss: 0.712\n",
            "[15,    10] loss: 0.702\n",
            "[16,    10] loss: 0.724\n",
            "[17,    10] loss: 0.700\n",
            "[18,    10] loss: 0.703\n",
            "[19,    10] loss: 0.718\n",
            "[20,    10] loss: 0.707\n",
            "[21,    10] loss: 0.690\n",
            "[22,    10] loss: 0.673\n",
            "[23,    10] loss: 0.694\n",
            "[24,    10] loss: 0.702\n",
            "[25,    10] loss: 0.692\n",
            "[26,    10] loss: 0.668\n",
            "[27,    10] loss: 0.698\n",
            "[28,    10] loss: 0.649\n",
            "[29,    10] loss: 0.699\n",
            "[30,    10] loss: 0.665\n",
            "3.3472564220428467 seconds\n",
            "Accuracy of the network on the 10000 test images: 52 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHolo90FK5XC",
        "outputId": "ca526664-4629-4f4c-c771-f84d4c86ff49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "net.fc3 = nn.Linear(net.fc3.in_features, 2)\n",
        "net.to(device_cpu)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 30\n",
        "\n",
        "train(net, epochs, criterion, optimizer, device_cpu, trainloader)\n",
        "test(net, device_cpu, testloader)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.790\n",
            "[2,    10] loss: 0.558\n",
            "[3,    10] loss: 0.504\n",
            "[4,    10] loss: 0.368\n",
            "[5,    10] loss: 0.385\n",
            "[6,    10] loss: 0.409\n",
            "[7,    10] loss: 0.341\n",
            "[8,    10] loss: 0.361\n",
            "[9,    10] loss: 0.349\n",
            "[10,    10] loss: 0.317\n",
            "[11,    10] loss: 0.383\n",
            "[12,    10] loss: 0.331\n",
            "[13,    10] loss: 0.340\n",
            "[14,    10] loss: 0.325\n",
            "[15,    10] loss: 0.259\n",
            "[16,    10] loss: 0.388\n",
            "[17,    10] loss: 0.304\n",
            "[18,    10] loss: 0.360\n",
            "[19,    10] loss: 0.244\n",
            "[20,    10] loss: 0.304\n",
            "[21,    10] loss: 0.355\n",
            "[22,    10] loss: 0.364\n",
            "[23,    10] loss: 0.302\n",
            "[24,    10] loss: 0.279\n",
            "[25,    10] loss: 0.346\n",
            "[26,    10] loss: 0.295\n",
            "[27,    10] loss: 0.332\n",
            "[28,    10] loss: 0.304\n",
            "[29,    10] loss: 0.374\n",
            "[30,    10] loss: 0.381\n",
            "3.1801741123199463 seconds\n",
            "Accuracy of the network on the 10000 test images: 80 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEh_MRs7LtSx"
      },
      "source": [
        "# **3. Do the same as in step 2 but use the pre-trained network resnet18 from the torch vision library. Compare the results.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DggkA5fVLFF5",
        "outputId": "3a1c6e42-de4c-4704-deb3-2c645357022a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_freezed = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model_freezed.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model_freezed.fc.in_features\n",
        "model_freezed.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_freezed.to(device_cpu)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 5\n",
        "\n",
        "train(model_freezed, epochs, criterion, optimizer, device_cpu, trainloader)\n",
        "test(model_freezed, device_cpu, testloader)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.934\n",
            "[2,    10] loss: 1.091\n",
            "[3,    10] loss: 1.084\n",
            "[4,    10] loss: 1.070\n",
            "[5,    10] loss: 0.843\n",
            "3.541722536087036 seconds\n",
            "Accuracy of the network on the 50 test images: 58.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2M_E9-6MYwQ",
        "outputId": "0311a335-ee0c-46e0-c933-6a4ead67a05e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model.to(device_cpu)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 5\n",
        "\n",
        "train(model, epochs, criterion, optimizer, device_cpu, trainloader)\n",
        "test(model, device_cpu, testloader)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.790\n",
            "[2,    10] loss: 0.697\n",
            "[3,    10] loss: 0.770\n",
            "[4,    10] loss: 0.801\n",
            "[5,    10] loss: 0.895\n",
            "9.76911735534668 seconds\n",
            "Accuracy of the network on the 50 test images: 46.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlEGbemOUx0n"
      },
      "source": [
        "# **4. Resnet18 was pre-trained on the image net data, which has an image resolution of 224x224. However, Resnet18 still works on other solutions because it uses an adaptive pooling layer before the fc-layer (see discussion here). Try to see if you can improve the results by resizing the CIFAR images to 224x224 before passing it to the Resnet.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f54_p4MxRwar",
        "outputId": "3b3fdbe8-84b9-4e62-e203-e747b8bb8701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), torchvision.transforms.Resize([224, 224])])\n",
        "\n",
        "#transforms.Resize((128,128),interpolation=Image.NEAREST\n",
        "                  \n",
        "trainset_resized = CIFAR_X(root='./data', train=True, download=True, transform = transform, exclude_list=[0,1,2,3,4,5,6,7])\n",
        "trainloader_resized = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset_resized = CIFAR_X(root='./data', train=False, download=True, transform = transform, exclude_list=[0,1,2,3,4,5,6,7])\n",
        "testloader_resized = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8a-qjqWUscZ",
        "outputId": "d7b976e7-1c54-45a9-bb3b-4e795f0c2d27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_resized = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model_resized.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "num_ftrs = model_resized.fc.in_features\n",
        "model_resized.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_resized.to(device_cpu)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 5\n",
        "\n",
        "train(model_resized, epochs, criterion, optimizer, device_cpu, trainloader_resized)\n",
        "test(model_resized, device_cpu, testloader_resized)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.780\n",
            "[2,    10] loss: 0.800\n",
            "[3,    10] loss: 0.749\n",
            "[4,    10] loss: 0.802\n",
            "[5,    10] loss: 0.814\n",
            "67.15398716926575 seconds\n",
            "Accuracy of the network on the 50 test images: 54.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JesY4s6DVwfg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}